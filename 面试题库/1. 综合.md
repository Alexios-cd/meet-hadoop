# 1.  简述对大数据组件：Yarn，Spark，Hbase，Hive的理解

Yarn可以理解为大数据组件运行job的管理器。

Spark分布式的利用内存进行分布式运算的大数据组件

Hbase是基于Hadoop的大数据常用数据库

Hive则是基于Hadoop的大数据数据仓库，操作跟关系数据库类似。

# 2. hdf文件系统中Namenode和DataNode区别和联系

Namenode存储了元数据，并且调度、协调整个集群

DataNode主要用来存储数据

# 3.请描述Spark RDD中的transform和action的理解

在Spark中，RDD（Resilient Distributed Datasets 弹性分布式数据集）是一种基本的数据结构，它代表一个**分布式**的、**不可变**的数据集合，可以跨多个计算节点进行并行处理。RDD提供了两种基本的操作类型：Transformations（转换）和Actions（行动）。

Transformations是一种RDD操作，用于从一个RDD中生成一个新的RDD。这个新的RDD不同于原始的RDD，因为它可能有不同的元素、分区、依赖关系或其他属性。Transformations是惰性计算的，即它们不会立即执行，而是等到一个Action被触发才会执行。Transformations包括map、filter、flatMap、union、join、reduceByKey等等。这些操作不会对原始RDD做出任何修改，而是返回一个新的RDD。

Actions是一种RDD操作，用于触发计算并返回结果。Actions会立即执行，并返回一个值或保存结果到外部存储介质中。Actions通常会涉及到计算RDD中所有的元素，它们是触发Spark进行计算的最终方法。常见的Actions包括count、collect、reduce、take、save等等。Actions执行后，Spark会将计算结果返回给Driver程序或保存到外部存储介质中。

总的来说，Transformations用于构建RDD的计算图，Actions用于触发计算图的执行。Transformations可以被链式组合在一起，形成一个DAG（有向无环图），而这个DAG可以被Spark用于优化计算和调度任务。理解Transformations和Actions的区别是非常重要的，因为这有助于提高Spark程序的性能和可读性。

# 4.分布式引发的问题

1. 死锁：至少有一个线程占用了资源，但是不占用CPU
2. 活锁：所有线程都没有把持资源，但是线程却是在不断地调度占用CPU
3. 需要引入一个管理节点
4. 为了防止入口的单点问题，需要引入管理节点的集群
5. 需要在管理阶段中选举出一个主节点
6. 需要确定一套选举算法
7. 主节点和从节点之间要保证数据的一致

# 5.hive与mysql（传统数据库）的区别

|              | Hive                                                         | Mysql                           |
| ------------ | ------------------------------------------------------------ | ------------------------------- |
| 查询语言     | hql                                                          | sql                             |
| 数据存储位置 | 数据存储在hdfs上                                             | 存储在自己的系统中              |
| 数据格式     | hive数据格式用户可以自定义                                   | mysql有自己的系统定义格式       |
| 数据更新     | hive不支持数据更新，只可以读，不可以写                       | sql支持数据更新                 |
| 索引         | hive没有索引，因此查询数据的时候是通过mapreduce很暴力的把数据都查询一遍，也造成了hive查询数据速度很慢，0.8版本之后加入索引 | mysql天然支持索引               |
| 延迟性       | hive延迟性高，MapReduce暴力遍历                              | mysql延迟性低                   |
| 数据规模     | hive存储的数据量超级大                                       | mysql只是存储一些少量的业务数据 |
| 底层执行原理 | hive底层是用的mapreduce                                      | mysql是excutor执行器            |



# 7.存储格式

**TextFile**
默认格式，按行存储，可以压缩但压缩文件不支持分片，反序列化开销是SequenceFile的几十倍（需要判断分隔符和换行符）

**SequenceFile**
hadoop原生支持，将kv以二进制方式按行存储，压缩后的文件支持压缩。默认以record压缩，可以改为block性能更好。压缩率很低，查询速度一般。

**RCFile**
按行分块、按列存储的存储方式，反序列化速度较慢，但压缩率和查询速度 快。

**ORC file**
RC的改良版，每个Task输出单文件、存储索引、支付复杂类型、支持块压缩、可以直接读取，ORC比RC高效很多。

--**Parquet**--
列式存储，是spark的默认存储格式，压缩和查询性能比ORC稍差，但是支持的编码更多，而且对嵌套式结构支持的更好（json）。

因此对结构化数仓来说ORC file格式更好，对灵活的spark作业来说Parquet格式更好。

## 8.压缩格式

上面虽然提到了压缩比，但只不过是相对于纯文本，在数据的存储方式上带来的数据量减少，并不是真正的压缩方式。
下方介绍在这些存储方式之上进一步减少数据量的压缩方式。

--**gzip**--
spark默认压缩方式，hadoop原生支持，压缩比率很高、压缩和解压速度很快，支持纯文本式编辑，使用方便，但是压缩后不支持分片，因此适用于1个块内大小的文件。

**lzo**
hadoop流行的压缩方式，需要安装，压缩解压速度较快，压缩率适中，建立索引后支持分片，压缩单个大文件时可以使用。

**snappy**
高速压缩和解压，压缩率较低，需要安装，不支持分片，推荐作为临时数据的压缩方式。

**bzip2**
非常高的压缩率，但解压速度很慢，支持分片。hadoop本身支持，但本地库不支持。一般和lzo选其中一个作为数据源的压缩格式。

# 9.介绍Yarm

通用资源管理系统和调度平台，可为上层应用提供统一的资源管理和调度。可以把yarn理解为相当于一个分布式的操作系统平台，而mapreduce等运算程序则相当于运行于操作系统之上的应用程序，Yarn为这些程序提供运算所需的资源（内存、cpu）。



YARN是一个资源管理、任务调度的框架，主要包含三大模块：ResourceManager（RM）、NodeManager（NM）、ApplicationMaster（AM）。

**ResourceManager ** 负责所有资源的监控、分配和管理；

**ApplicationMaster** 负责每一个具体应用程序的调度和协调；

**NodeManager** 负责每一个节点的维护。

对于所有的Applications，ResourceManager拥有绝对的控制权和对资源的分配权。而每个ApplicationMaster则会和ResourceManager协商资源，同时和NodeManager通信来执行和监控Task。

**ResourceManager**

ResourceManager负责整个集群的资源管理和分配，是一个全局的资源管理系统。
NodeManager以心跳的方式向ResourceManager汇报资源使用情况（目前主要是CPU和内存的使用情况）。RM只接受NM的资源回报信息，对于具体的资源处理则交给NM自己处理。
YARN Scheduler根据application的请求为其分配资源，不负责application job的监控、追踪、运行状态反馈、启动等工作。

**NodeManager**

NodeManager是每个节点上的资源和任务管理器，它是管理这台机器的代理，负责该节点程序的运行，以及该节点资源的管理和监控。YARN集群每个节点都运行一个NodeManager。
NodeManager定时向ResourceManager汇报本节点资源（CPU、内存）的使用情况和Container的运行状态。当ResourceManager宕机时NodeManager自动连接RM备用节点。
NodeManager接收并处理来自ApplicationMaster的Container启动、停止等各种请求。

**ApplicationMaster**

用户提交的每个应用程序均包含一个ApplicationMaster，它可以运行在ResourceManager以外的机器上。
负责与RM调度器协商以获取资源（用Container表示）。
将得到的任务进一步分配给内部的任务(资源的二次分配)。
与NM通信以启动/停止任务。
监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。
当前YARN自带了两个ApplicationMaster实现，一个是用于演示AM编写方法的实例程序DistributedShell，它可以申请一定数目的Container以并行运行一个Shell命令或者Shell脚本；另一个是运行MapReduce应用程序的AM—MRAppMaster。
注：RM只负责监控AM，并在AM运行失败时候启动它。RM不负责AM内部任务的容错，任务的容错由AM完成

# 10. kettle 和Lambda有什么架构区别

1. Kettle是一种ETL工具，用于抽取、转换和加载数据。它包含了一系列的组件，如Spoon、Pan和Kitchen等。使用Kettle可以快速地构建数据仓库和数据集成系统。
2. Lambda架构是一种处理大数据的架构，它结合了批处理和流处理两种处理方式。Lambda架构的核心是一个可扩展的、分布式的、实时的数据处理系统，它可以同时处理实时数据和历史数据。
3. Kettle和Lambda的架构区别在于它们的设计目标不同。Kettle主要用于数据的批处理和集成，而Lambda主要用于实时数据处理和分析。
4. Kettle和Lambda的实现技术也不同。Kettle使用的是基于图形化界面的ETL工具，而Lambda使用的是基于分布式数据处理框架的架构。
5. Kettle和Lambda的应用场景也不同。Kettle适用于数据仓库、数据集成和数据转换等场景，而Lambda适用于实时数据分析、实时数据处理和实时数据可视化等场景。
