# 1. 讲述一下HDFS上传文件的流程

1. 由客户端 向 NameNode 节点 发出上传文件请求;
2. NameNode 向Client返回可以可以存数据的 DataNode ;

3. 客户端 首先 根据返回的信息 先将 文件分块(Hadoop2.X版本 每一个block为 128M 而之前的版本为 64M;

4. 然后通过NameNode返回的DataNode信息 直接发送给DataNode 并且是 流式写入同时会复制到其他两台机器;

5. dataNode 向 Client通信 表示已经传完 数据块 同时向NameNode报告 

6. 依照上面(④到⑤)的原理将 所有的数据块都上传结束   向 NameNode 报告 表明 已经传完所有的数据块 

# 2.Hadoop的文件读流程和写流程

1、**读流程**：

1. 客户端发起RPC请求访问NameNode
1. NameNode查询元数据，找到这个文件的存储位置对应数据块的信息
1. NameNode将文件对应的数据块的节点地址的全部或者部分放入一个队列中然后返回
1. client收到这个数据块对应的节点地址
1. client会从队列中取出第一个数据块对应的节点地址，会从这些节点地址中选取一个最近的节点进行读取
1. 将Block读取之后，对Block进行shecksum的验证，如果验证失败，说明数据块产生损坏，那么client会向NameNode发送信息说明该节点上的数据块损坏，然后从其他节点中再次读取这个数据块
1. 验证成功，则从队列中取出下一个Block的地址，然后继续读取
1. 当把这一次的文件快全部读取完成之后，client会向NameNode要下一批Block的地址
1. 当把文件全部读取完成之后，从client会向NameNode发送一个读取完毕的信号，，NameNode就会关闭对应的文件

2、**写流程**：

1. client发送RPC请求给NameNode
1. NameNode接收到请求之后，对请求进行验证，例如这个请求中的文件是否存在，再例如权限验证
1. 如果验证通过，NameNode确定文件的大小以及分块的数量，确定对应的节点（会去找磁盘空间相对空闲的节点来使用），将节点地址放入队列中返回
1. 客户端收到地址以后，从队列中依次取出节点地址，然后数据块依次放入对应的节点地址上
1. 客户端在写完之后就会向NameNode发送写完数据的信号，NameNode会给客户端一个关闭文件的信号
1. DataNode之间将会通过管道进行自动备份，保证复本数量

# 3.SecondaryNameNode的作用

NameNode职责是管理元数据信息，DataNode的职责是负责数据具体存储，那么SecondaryNameNode的作用是什么？

答：它的职责是合并NameNode的edit logs到fsimage文件。

 每达到触发条件 [达到一个小时，或者事物数达到100万]，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，并加载到内存进行merge（这个过程称为checkpoint）

# 4.HDFS小文件问题及解决方案

小文件是指文件size小于HDFS上block大小的文件。这样的文件会给

hadoop的扩展性和性能带来严重问题。首先，在HDFS中，任何block，文件或者目录在内存中均以对象的形式存储，每个对象约占150byte，如果有1000 0000个小文件，每个文件占用一个block，则namenode大约需要2G空间。如果存储1亿个文件，则namenode需要20G空间。这样namenode内存容量严重制约了集群的扩展。其次，访问大量小文件速度远远小于访问几个大文件。HDFS最初是为流式访问大文件开发的，如果访问大量小文件，需要不断的从一个datanode跳到另一个datanode，严重影响性能。最后，处理大量小文件速度远远小于处理同等大小的大文件的速度。每一个小文件要占用一个task，而task启动将耗费大量时间甚至大部分时间都耗费在启动task和释放task上。

**对于小文件问题，Hadoop本身也提供了几个解决方案，分别为：Hadoop Archive，Sequence file和CombineFileInputFormat。**

1.**Hadoop Archive:** Hadoop Archive或者HAR，是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样在减少namenode内存使用的同时，仍然允许对文件进行透明的访问。
HAR是在Hadoop file system之上的一个文件系统，因此所有fs shell命令对HAR文件均可用，只不过是文件路径格式不一样
使用HAR时需要两点，第一，对小文件进行存档后，原文件并不会自动被删除，需要用户自己删除；第二，创建HAR文件的过程实际上是在运行一个mapreduce作业，因而需要有一个hadoop集群运行此命令。

此外，HAR还有一些缺陷：第一，一旦创建，Archives便不可改变。要增加或移除里面的文件，必须重新创建归档文件。第二，要归档的文件名中不能有空格，否则会抛出异常，可以将空格用其他符号替换

**2.sequence file** ：sequence file由一系列的二进制key/value组成，如果为key小文件名，value为文件内容，则可以将大批小文件合并成一个大文件。

**3.CombineFileInputFormat**：CombineFileInputFormat是一种新的inputformat，用于将多个文件合并成一个单独的split