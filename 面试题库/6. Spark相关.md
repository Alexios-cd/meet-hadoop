# 1.宽依赖和窄依赖

在Spark中，"宽依赖"和"窄依赖"是用来描述在转换操作中一个RDD（弹性分布式数据集）依赖于其他RDD的方式。

**窄依赖（Narrow Dependency）**指的是一个父RDD的每个分区最多被一个子RDD的一个分区所依赖，也就是说，每个父RDD分区中的数据只会被一个子RDD分区所使用。这种依赖关系在转换操作时，Spark可以同时处理父RDD和子RDD的相应分区中的数据，而不需要进行任何数据重组。这使得计算过程效率更高。例如，Map、filter、union、join等操作都可以建立窄依赖关系。

**宽依赖（Wide Dependency）**指的是一个父RDD的每个分区可以被多个子RDD的分区所依赖，也就是说，每个父RDD分区中的数据可以被多个子RDD分区所使用。这种依赖关系在转换操作时，Spark需要对父RDD中的数据进行数据重组以满足子RDD的需要。这会导致在Spark集群中进行数据传输和大量磁盘读写操作，从而降低计算效率。例如，ReduceByKey等聚合操作会建立宽依赖关系。

从父RDD和子RDD的关系来看，窄依赖表示每个父RDD分区最多只有一个子RDD分区依赖，即一对一或多对一的关系。而宽依赖表示一个父RDD分区可以有多个子RDD分区依赖，即多对一的关系。在转换操作中，宽依赖关系会导致数据的洗牌和重组，会增加通信开销和处理时间，因此在性能优化时需要尽量避免宽依赖关系的产生。

![image-20230216140648153](./assets/image-20230216140648153.png)



# 2.Transformation和action算子

在Spark中，算子可分为两类：Transformation和Action。

- Transformation是指对RDD进行转换操作，生成一个新的RDD，但不会触发任何实际的计算，即懒执行，需要等到Action算子被调用时才会触发计算。

  - eg：map, filter

- Action是指对RDD进行实际计算并返回结果的操作。

  - eg：count

# 3.spark shuffle原理和特性

在Spark中，Shuffle是一种非常重要的机制，用于**在不同节点之间重新分配数据**，并将相关数据合并到一个节点上。下面简述一下Spark Shuffle的原理和特性：

**Shuffle原理**：

当Spark需要对一个RDD进行重新分区或者进行一些聚合计算时，就需要进行Shuffle操作。Shuffle的过程可以分为两个阶段：Map阶段和Reduce阶段。在Map阶段，Spark会对每个节点上的数据进行本地聚合，然后按照Key将数据划分到不同的节点上；在Reduce阶段，Spark会将相同Key的数据合并到同一个节点上，并进行最终的计算。

在Shuffle过程中，数据的传输和存储都非常耗费资源。因此，Spark采用了一些优化策略来提高Shuffle的性能，例如：

1. 对Map输出进行本地聚合，减少数据的传输量。
2. 尽量将相同Key的数据放到同一个分区中，减少数据的传输量。
3. 对于合并时需要进行排序的数据，可以使用分治的思想进行局部排序，从而减少数据的传输量。

**Shuffle特性：**

1. Shuffle是Spark中的一个非常耗费资源的操作，因此需要尽量避免不必要的Shuffle操作。
2. Shuffle过程中需要进行网络传输和磁盘IO操作，因此对于大规模数据的处理，可能会成为瓶颈。
3. 在Shuffle过程中，可以进行一些优化操作，例如对Map输出进行本地聚合、尽量将相同Key的数据放到同一个分区中、使用分治思想进行局部排序等，从而提高Shuffle的性能。
4. Shuffle过程中的一些参数设置，例如分区数、缓存大小等，也会影响Shuffle的性能。因此，在进行性能优化时，需要根据实际情况对这些参数进行调整。

# 4.  什么情况下会触发Spark的shuffle

Spark中的Shuffle是一种代价昂贵的操作，因此需要尽量避免不必要的Shuffle操作。一般情况下，Spark会在以下几种情况下触发Shuffle：

1. **对数据进行重分区**：当调用`repartition`或`coalesce`等转换算子时，需要对数据进行重分区操作，会触发Shuffle。
2. **对数据进行聚合操作**：例如调用`groupByKey`、`reduceByKey`、`aggregateByKey`等转换算子，需要对相同Key的数据进行合并操作，会触发Shuffle。
3. **对数据进行排序操作**：例如调用`sortByKey`、`join`等转换算子，需要对数据进行排序操作，会触发Shuffle。
4. 在**调用`Window`函数进行滑动窗口计算**时，如果窗口间存在重叠，也会触发Shuffle。

需要注意的是，虽然在上述情况下会触发Shuffle，但是Spark会尽量避免不必要的Shuffle操作，采用一些优化策略来提高Shuffle的性能，例如对Map输出进行本地聚合、尽量将相同Key的数据放到同一个分区中、使用分治思想进行局部排序等。因此，在编写Spark应用程序时，应该尽量避免不必要的Shuffle操作，以提高程序的性能。

#  5. 简述Spark广播变量

Spark的广播变量（broadcast variable）是一种**用于在各个节点之间共享只读数据的机制**。它可以**让每个节点在任务执行期间只获取一份数据副本，避免在每次任务执行时重复传输数据，从而提高任务执行的效率**。

广播变量适用于以下两种情况：

1. 对于**较小的数据集**，需要在各个节点之间共享，例如字典表、配置文件等。
2. 在**每个任务中需要使用相同的数据**，但不希望在每个任务执行时都重新加载数据，例如模型参数、全局计数器等。

使用广播变量可以提高任务的执行效率，因为数据只需要在集群中传输一次，并且可以被缓存到内存中。如果数据集较大或不适合在内存中缓存，则不适合使用广播变量。

广播变量的使用限制如下：

1. 广播变量的值必须是只读的，不能被修改。
2. 广播变量的值必须是序列化的，可以使用Java的序列化机制或Kryo进行序列化。
3. 广播变量的值必须足够小，以便可以在内存中缓存。通常建议广播变量的大小不要超过10MB。

广播变量的使用方法如下：

1. 使用`SparkContext`的`broadcast`方法创建广播变量。
2. 在任务中使用广播变量的`value`属性来获取广播变量的值。

下面是一个使用广播变量的例子，假设我们需要在多个任务中共享一个字典表：

```scala
// 创建字典表
val dictionary = Map("apple" -> 1, "orange" -> 2, "banana" -> 3)

// 广播字典表
val broadcastDict = sc.broadcast(dictionary)

// 在任务中使用字典表
val data = sc.parallelize(Seq("apple", "orange", "banana"))
val result = data.map(x => broadcastDict.value.getOrElse(x, 0)).collect()

// 打印结果
println(result)
```

在这个例子中，我们首先创建了一个字典表`dictionary`，然后使用`sc.broadcast`方法将其广播。在任务中，我们使用`broadcast_dict.value`属性来获取字典表，并对数据进行处理。最后，使用`collect`方法获取处理结果。

# 6.Spark任务提交流程

1. **打包Spark应用程序**：将应用程序代码打包成一个JAR文件或Python egg文件，包括应用程序所依赖的库文件。
1. **提交Spark应用程序**：使用Spark自带的命令行工具或API将打包好的应用程序提交到Spark集群。在提交应用程序时，可以指定应用程序的配置信息、依赖库等。
1. **Spark集群启动应用程序**：Spark集群接收到应用程序提交请求后，会根据应用程序的配置信息和资源需求，为应用程序分配资源，并启动应用程序的Driver进程。
1. **Driver进程启动任务**：Driver进程是Spark应用程序的主进程，负责调度任务和协调不同节点上的计算。Driver进程会将任务分配给不同的Worker节点，并控制任务的执行。
1. **Worker节点执行任务**：Worker节点接收到任务后，会启动Executor进程执行任务。Executor进程负责计算和数据处理，并将结果返回给Driver进程。
1. **应用程序执行完毕**：当应用程序执行完毕后，Driver进程会将结果汇总，并将最终结果返回给应用程序的调用者。

# 7.spark schedule（任务调度）

在Spark中，任务调度是将不同的任务分配给不同的节点执行的过程。Spark中的任务调度分为两个层次：集群层面的资源管理和应用层面的任务调度。

1. 集群层面的资源管理：Spark采用了基于YARN、Mesos或Standalone的资源管理器来管理集群中的资源。资源管理器负责对集群中的CPU、内存等资源进行分配和调度，为Spark应用程序提供资源支持。
2. 应用层面的任务调度：在Spark应用程序中，任务调度由Driver进程负责。Driver进程负责将应用程序分解成不同的任务，并根据任务之间的依赖关系和数据分区情况，将任务分配给不同的Executor进程执行。

Spark中的任务调度采用了DAG（有向无环图）的方式来描述任务之间的依赖关系，使得任务之间的执行顺序可以被正确地确定。Spark将DAG图分解成不同的阶段，每个阶段包含多个任务，任务之间无依赖关系。任务执行的顺序是按照阶段进行，每个阶段执行完毕后才能执行下一个阶段。

任务调度的过程包括以下步骤：

1. Driver进程将Spark应用程序分解成DAG图。
2. Driver进程将DAG图分解成多个阶段，每个阶段包含多个任务。
3. Driver进程根据任务之间的依赖关系和数据分区情况，将任务分配给不同的Executor进程执行。
4. Executor进程按照任务的分配情况执行任务，将结果返回给Driver进程。
5. 当一个阶段中的所有任务执行完毕后，Driver进程会将下一个阶段的任务分配给Executor进程。
6. 当所有任务执行完毕后，Driver进程会将结果汇总，并将最终结果返回给应用程序的调用者。

Spark任务调度的实现使用了多种技术，包括任务分区、数据分区、shuffle等，以保证任务的执行效率和正确性。同时，Spark还提供了多种调度策略，如FIFO、Fair、Deadline等，以满足不同应用场景的需求。

# 8. Spark cache一定能提升计算性能么？说明原因？

不一定，cache是将数据缓存到内存里，当小数据量的时候是能提升效率，但数据大的时候内存放不下就会报溢出。

# 9. Cache和persist有什么区别和联系？

cache调用了persist方法，cache只有一个默认的缓存级别MEMORY_ONLY ，而persist可以根据情况设置其它的缓存级别。


# 10. RDD是弹性数据集，“弹性”体现在哪里呢？你觉得RDD有哪些缺陷？

RDD（Resilient Distributed Datasets）是Spark的核心数据抽象，是一个可跨多个节点并行操作的不可变分布式数据集。RDD的“弹性”体现在以下两个方面：

1. 容错性：当一个节点发生故障时，Spark可以自动将受影响的RDD分区重新计算，并将结果存储在备份节点上，从而保证计算结果的可靠性和一致性。
2. 数据集的自动分区和内存管理：Spark可以自动将数据集分成多个分区，使得每个分区可以在不同节点上并行处理，从而充分利用集群的计算资源。同时，Spark还会自动将RDD中的数据缓存在内存中，以加快后续操作的速度。

虽然RDD具有很多优点，例如容错性、易于编程、高效的内存管理等，但是它也存在一些缺陷：

1. 不支持原子更新：由于RDD是不可变的，因此不支持原子更新，这意味着在并发情况下，需要使用锁来保护共享数据。
2. 内存占用较高：由于RDD需要缓存数据，因此对于较大的数据集，需要占用大量的内存，这可能会导致性能下降或OOM（Out Of Memory）错误。
3. 低效的磁盘IO：当RDD的数据无法全部存储在内存中时，Spark需要将数据从磁盘读取到内存中进行计算，这可能会导致磁盘IO成为瓶颈，从而降低计算性能。
4. 不适合迭代计算：由于每次对RDD进行转换操作都需要重新计算整个数据集，因此对于需要多次迭代计算的场景，由于RDD不支持缓存和复用中间结果，RDD的性能可能不如其他更适合迭代计算的数据抽象，例如DataFrame和Dataset。

# 11.Spark中repartition和coalesce

```scala
repartition(numPartitions:Int):RDD[T]
coalesce(numPartitions:Int, shuffle:Boolean=false):RDD[T]
```

在Spark中，`repartition`和`coalesce`都是用来重新分区（或合并分区）的操作，它们的作用是改变数据集的分区数，从而对后续的计算产生影响。它们的区别在于分**区的数量调整方式**和**可用性**。

**`repartition`操作可以用于增加或减少RDD的分区数量**，其内部实现是通过先进行`shuffle`（洗牌）操作将RDD重新分区，然后再缓存到内存或磁盘中。当我们需要增加分区数时，`repartition`会通过随机重新分配数据来增加分区数，而当我们需要减少分区数时，`repartition`会将相邻的分区合并为一个分区，从而减少分区数。由于`repartition`需要进行`shuffle`操作，因此**它的开销比较大，适用于大规模的数据集**。

**`coalesce`操作用于减少RDD的分区数量**，其内部实现是将一些相邻的分区合并为一个分区，不会进行`shuffle`操作，因此开销较小。需要注意的是，`coalesce`不能增加RDD的分区数量，它只能减少分区数。由于`coalesce`不进行`shuffle`操作，因此只能将相邻的分区合并，因此在某些情况下，合并后的分区不一定是等大小的。coalesce 的第一个参数`numPartitions`必须小于或等于原始RDD的分区数，否则`coalesce`操作将不起作用。

# 12.Groupbykey和Reducebykey哪个性能更高，为什么？

在Spark中，`groupByKey`和`reduceByKey`都是用于对键值对RDD进行分组的操作，但它们的实现方式和性能表现有所不同。

`groupByKey`操作将RDD中的键值对按照键进行分组，得到一个新的RDD，每个元素都是一个键值对的序列。这个操作比较耗费资源，因为它需要在网络上将具有相同键的数据重新分配到同一个节点上，然后再将它们进行排序和组合。由于`groupByKey`操作需要在网络上进行数据洗牌（shuffle）操作，因此开销较大，适用于数据量较小的情况。

相比之下，`reduceByKey`操作将RDD中具有相同键的元素归约到一起，然后对每个键对应的值进行合并。这个操作可以避免在网络上进行数据洗牌操作，因为**它在每个节点上先对本地的数据进行局部合并，然后再将各个节点的结果进行汇总**。因此，`reduceByKey`操作的性能通常比`groupByKey`更好，特别是对于大数据集。

总的来说reduceByKey适用于大规模数据的聚合操作，而groupByKey适用于小规模数据的分组操作。

# 13.Spark相比MapReduce的计算模型有哪些区别？

1. spark处理数据是基于内存的，而MapReduce是基于磁盘处理数据的。
2. Spark在处理数据时构建了DAG有向无环图，减少了shuffle和数据落地磁盘的次数
3. Spark是粗粒度资源申请，而MapReduce是细粒度资源申请
4. 支持更多的数据源：Spark支持更多的数据源，例如HDFS、本地文件、HBase、Cassandra等，而MapReduce主要是针对HDFS进行数据处理。
5. 更多的操作：Spark提供了很多高阶函数，例如map、reduce、filter、join等，而MapReduce只提供了Map和Reduce操作。
6. 运行速度：由于Spark的内存计算和DAG计算模型，使得Spark的运行速度比MapReduce更快。
7. 运行模式：Spark支持交互式计算和流式计算，可以进行实时分析和处理，而MapReduce主要是批处理模式。

# 14.Spark如何解决数据倾斜问题

1. 先用sample(false,0.x)采样key，找出倾斜的key
2. 把数据集拆成倾斜的部分和不倾斜的部分，不倾斜的部分走正常流程
3. 倾斜的部分key前面加上一个定长的随机字符串，然后执行重分区
4. 重分区后进行一个聚合操作，然后去除定长前缀再聚合一次。
5. 如果是大表join大表，其中一个表有数据倾斜，就需要用膨胀法，将倾斜部分的key加上一个0-n的前缀，一条数据膨胀成n条，然后将另一个表的这部分key也加上相应的前缀，然后单独对这部分数据进行一次双重聚合，与不倾斜的数据进行union操作，完成聚合。
6. 空值看作是特殊的key，空值多了一样用3的方法去解决。
