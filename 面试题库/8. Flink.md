# 1. Flink如何保证精确一次性消费

Flink 保证精确一次性消费的主要方式是使用“exactly-once”语义。这意味着 Flink 可以确保每个输入数据只被处理一次，即使在出现故障的情况下也是如此。

具体来说，Flink 通过以下方式保证精确一次性消费：

1. **原子性快照**：Flink 使用 checkpoint 来记录处理状态，以便在发生故障时恢复状态。每个 checkpoint 都是原子性的，这意味着它们要么完全成功，要么完全失败。这样可以确保每个输入数据只被处理一次，并且在故障恢复后不会重复处理。
2. **状态后退**：当发生故障时，Flink 可以使用 checkpoint 恢复到之前的状态，从而避免重复处理数据。这种方式被称为“状态后退”。
3. **事务性写入**：Flink 还支持事务性写入，这意味着在写入外部系统时，只有在整个事务成功提交后，才会将数据写入外部系统。如果事务失败，则数据不会写入外部系统。这可以确保每个输入数据只被写入一次。

综上所述，Flink 通过使用 checkpoint、状态后退和事务性写入等方式，来保证精确一次性消费。

**Checkpoint机制** 主要是当Flink开启Checkpoint的时候，会往Source端插入一条barrir，然后这个barrir随着数据流向一直流动，当流入到一个算子的时候，这个算子就开始制作checkpoint，制作的是从barrir来到之前的时候当前算子的状态，将状态写入状态后端当中。然后将barrir往下流动，当流动到keyby 或者shuffle算子的时候，例如当一个算子的数据，依赖于多个流的时候，这个时候会有barrir对齐，也就是当所有的barrir都来到这个算子的时候进行制作checkpoint，依次进行流动，当流动到sink算子的时候，并且sink算子也制作完成checkpoint会向jobmanager 报告 checkpoint n 制作完成。

**二阶段提交机制** Flink 二阶段提交机制是 Flink 在确保精确一次性消费时使用的一种方式。它主要用于将数据写入外部系统，例如数据库或消息队列.

1. **预提交**：在写入外部系统之前，Flink 会先将数据写入内部缓冲区，这个过程称为“预提交”。在预提交阶段，Flink 会生成一个唯一的事务 ID，并将其发送给外部系统，告诉外部系统即将开始一个新的事务。
2. **提交请求**：一旦预提交成功，Flink 就会向外部系统发送一个“提交请求”，告诉外部系统可以将数据写入外部系统了。在此期间，Flink 会等待外部系统的响应，以确保外部系统已准备好接受数据。
3. **事务提交**：如果外部系统已准备好接受数据，则会将数据写入外部系统，并向 Flink 发送一个“事务提交”响应。如果响应成功，则 Flink 将提交该事务，并将其标记为已完成。
4. **事务回滚**：如果在提交请求期间外部系统发生了故障，或者外部系统在提交请求后未能成功写入数据，则会向 Flink 发送一个“事务回滚”响应。在这种情况下，Flink 将回滚该事务，并将其标记为已失败。

总的来说，Flink 二阶段提交机制通过将写入外部系统的过程分为预提交和提交请求两个阶段，并使用事务 ID 来跟踪事务状态，来确保在写入外部系统时的精确一次性消费。

# 2. flink和spark区别

flink是一个类似spark的“开源技术栈”，因为它也提供了批处理，流式计算，图计算，交互式查询，机器学习等。flink也是内存计算，比较类似spark，但是不一样的是，spark的计算模型基于RDD，将流式计算看成是特殊的批处理，他的DStream其实还是RDD。而flink把批处理当成是特殊的流式计算，但是批处理和流式计算的层的引擎是两个，抽象了DataSet和DataStream。flink在性能上也表现的很好，流式计算延迟比spark少，能做到真正的流式计算，而spark只能是准流式计算。而且在批处理上，当迭代次数变多，flink的速度比spark还要快，所以如果flink早一点出来，或许比现在的Spark更火。


# 3. Flink的状态可以用来做什么

Flink 的状态是指在 Flink 应用程序中维护的数据或状态信息，它可以用于许多不同的目的，包括：

1. **记录历史数据**：Flink 的状态可以用于记录历史数据，例如在流式应用程序中，可以使用状态来记录每个事件的状态，以便在后续处理中使用。
2. **聚合数据**：Flink 的状态可以用于聚合数据，例如在流式应用程序中，可以使用状态来维护一个计数器或求和器，以便在处理数据时聚合数据。
3. **实时查询**：Flink 的状态可以用于实时查询，例如在流式应用程序中，可以使用状态来维护一个实时的聚合数据，以便在接收到查询请求时能够快速响应。
4. **事件驱动应用程序**：Flink 的状态可以用于事件驱动应用程序，例如在事件驱动的应用程序中，可以使用状态来维护应用程序的状态，以便在接收到事件时能够更新应用程序的状态。
5. **机器学习**：Flink 的状态可以用于机器学习，例如在机器学习应用程序中，可以使用状态来维护模型参数，以便在接收到新的数据时能够更新模型。

总的来说，Flink 的状态可以用于许多不同的目的，它可以帮助开发人员实现复杂的流式应用程序，并使应用程序能够处理大量的数据和事件。

# 4. Flink的waterMark机制，Flink watermark传递机制

Flink 的 Watermark 机制是用于处理Event Time的一种机制，它用于确定Event Time流的进度，并确保在处理数据时，不会处理过期的数据。

1. Watermark 定义：Watermark 是一个特殊的事件，它表示在 Watermark 时间之前的所有事件都已到达。例如，如果一个 Watermark 的时间戳为 10:00:00，则表示在该时间戳之前的所有事件都已到达。
2. Watermark 生成：在流式应用程序中，Flink 会周期性地生成 Watermark，以便确定Event Time流的进度。Watermark 的生成方式通常是通过源操作符来实现的。
3. Watermark 传递：在 Flink 中，Watermark 是通过数据流传递的。当一个 Watermark 到达一个算子时，算子会将其向下传递，以便下游算子可以使用它来确定Event Time流的进度。
4. Watermark 处理：当一个算子接收到一个 Watermark 时，它会将其与自己维护的状态进行比较，以确定是否可以处理一些过期的数据。如果算子可以处理过期的数据，则会将其发送到下游算子进行处理。

总的来说，Flink 的 Watermark 机制是用于处理Event Time的一种机制，它可以帮助开发人员确保在处理数据时不会处理过期的数据，从而提高流式应用程序的准确性和效率。

在多并行度中，例如在kafka中会所有的分区都达到才会触发窗口

# 5. Flink的时间语义

Event Time 事件产生的时间

Ingestion time 事件进入Flink的时间

Processing time 事件进入算子的时间

# 6. Flink的运⾏架构

![在这里插入图片描述](./assets/156bb1ed5fa44855b0469d9d639d2256.png)

当 Flink 集群启动后，⾸先会启动⼀个 JobManger 和⼀个或多个的 TaskManager。

1. 由 Client 提交任务给JobManager，JobManager 再调度任务到各个 TaskManager 去执⾏，然后 TaskManager 将⼼跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进⾏数据的传输。上述三者均为独⽴的 JVM 进程。
2. Client 为提交 Job 的客户端，可以是运⾏在任何机器上（与 JobManager 环境连通即可）。提交 Job 后，Client 可以结束进程（Streaming的任务），也可以不结束并等待结果返回。
3. JobManager 主要负责调度 Job 并协调 Task 做 checkpoint。从 Client 处接收到 Job 和 JAR 包等资源后，会⽣成优化后的执⾏计划，并以 Task 的单元调度到各个 TaskManager 去执⾏。
4. TaskManager 在启动的时候就设置好了槽位数（Slot），每个 slot 能启动⼀个 Task，Task 为线程。从JobManager 处接收需要部署的 Task，部署启动后，与⾃⼰的上游建⽴ Netty 连接，接收数据并处理。

# 7. Flink的作业执⾏流程

以yarn模式Per-job⽅式为例概述作业提交执⾏流程

1. 当执⾏executor() 之后,会⾸先在本地client 中将代码转化为可以提交的 JobGraph，如果提交为Per-Job模式,则⾸先需要启动ApplicationMaster, client会⾸先向资源系统申请资源, 在yarn下即为申请container，开启ApplicationMaster, 如果是Session模式的话则不需要这个步骤
1. Yarn分配资源, 开启ApplicationMaster
1. Client将Job提交给Dispatcher
1. Dispatcher 会开启⼀个新的 JobManager线程
1. JobManager向Flink ⾃⼰的 Resourcemanager申请slot资源来执⾏任务
1. ResourcesMananger向 Yarn申请资源来启动 TaskManger (Session模式跳过此步)
1. Yarn 分配 Container 来启动 taskManger (Session模式跳过此步)
1. Flink 的 ResourcesMananger向 TaskManager 申请 slot资源来启动 task
1. TaskManager 将待分配的 slot 提供给 JM
1. JobManager提交 task, TaskManager 会启动新的线程来执⾏任务,开始启动后就可以通过 shuffle模块进⾏ task之间的数据交换



# 8. kafka消费者组

Kafka消费者组是一组消费者实例，它们共同消费同一主题的消息。消费者组的作用是提高消费者的可扩展性和容错性。

1. **提高消费者的吞吐量**：消费者组可以将消息分配给多个消费者实例，从而实现高吞吐量的消费。
1. **提高消费者的容错性**：当某个消费者实例发生故障时，消费者组中的其他实例可以接替它继续消费消息。
2. **实现消息的负载均衡**：消费者组可以根据消费者实例的数量和负载情况，动态地分配消息，从而实现消息的均衡消费。
3. **支持消费者的水平扩展**：通过增加消费者实例，消费者组可以实现对消息处理能力的水平扩展。

总之，消费者组是Kafka中重要的概念，它可以帮助我们更好地管理和利用消息队列中的消息。





# 9. kafka如何保证数据不丢失，不重复消费？

Kafka 通过多个机制来保证数据不丢失，不重复消费：

1. **内部副本机制**：Kafka 采用主题分区的方式对消息进行存储和复制。每个分区都有多个副本，其中一个副本为 leader，负责接收和处理消息，其他副本为 follower，用于备份和容错。当 leader 副本发生故障时，Kafka 会自动将其中一个 follower 副本提升为 leader，从而保证数据不丢失。
2. **确认机制**：Kafka 允许消费者在消费消息时进行确认操作，即消费者可以向 Kafka 发送确认消息，告诉 Kafka 已经成功消费了某个消息。Kafka 会记录每个消费者消费的消息偏移量，以便在发生故障时进行恢复。
3. **消费者组机制**：Kafka 允许多个消费者组同时消费同一主题的消息，每个消费者组内部的消费者实例共同消费消息。消费者组机制可以保证同一条消息只会被同一个消费者组中的一个消费者实例消费，从而避免重复消费。
4. **水位线机制**：Kafka 支持事件时间语义，即每条消息都有一个时间戳。Kafka 通过水位线机制来保证消息的顺序性和准确性。消费者在消费消息时，可以通过水位线机制来判断哪些消息已经到达，哪些消息还需要等待，从而保证不会重复消费和丢失消息。

Kafka 通过内部副本机制、确认机制、消费者组机制和水位线机制等多种机制来保证数据不丢失，不重复消费。









# 10. Kafka消息堆积如何处理？

Kafka 消息堆积是指由于消费者处理消息速度慢或者消费者宕机等原因，导致未被及时消费的消息积累在 Kafka 中，从而导致 Kafka 中的消息堆积越来越严重的情况。

处理 Kafka 消息堆积的方式：

1. **增加消费者**：增加消费者数量可以提高消息的消费速度，从而减少消息堆积。可以通过增加消费者实例或者增加消费者组的方式来实现。

2. **增加分区**：增加主题的分区数量可以提高消息的并行处理能力，从而减少消息堆积。需要注意的是，增加分区会导致已有消息的重新分配，可能会影响消费者的消费进度和消息的顺序性。

3. **调整消费者参数**：可以通过调整消费者的参数来提高消费者的处理能力，如增加消费者的堆内存、调整消费者的线程数等。

4. **增加 Kafka 集群节点**：增加 Kafka 集群节点可以提高 Kafka 的并行处理能力，从而减少消息堆积。需要注意的是，增加节点需要考虑硬件资源、网络带宽等因素。

5. **手动消费**：如果消息堆积已经严重，可以考虑使用手动消费的方式，通过消费者 API 手动消费消息，从而加快消息的消费速度。

6. **提高消费者能力**：优化消费者代码，提高消费者能力。

需要注意的是，处理 Kafka 消息堆积需要根据具体的业务场景和数据特点来选择合适的方式，同时需要考虑消费者的消费能力、Kafka 集群的性能和可用性等因素。





# 11. ClinkHouse去重问题？

ClickHouse 的去重问题主要是由于分布式架构和分布式计算的特性导致的。在 ClickHouse 中，数据会被分布到多个节点上进行存储和计算，因此在进行查询时，可能会出现重复数据的情况。

为了解决 ClickHouse 的去重问题，可以采用以下几种方式：

1. **使用 DISTINCT 关键字**：在查询语句中添加 DISTINCT 关键字，可以去除结果集中的重复数据。例如：SELECT DISTINCT * FROM table_name。
2. **使用 GROUP BY 关键字**：在查询语句中添加 GROUP BY 关键字，可以将结果集按照指定的字段进行分组，并去除重复数据。例如：SELECT field1, field2, COUNT(*) FROM table_name GROUP BY field1, field2。
3. **使用 DISTINCTIF 函数**：ClickHouse 提供了 DISTINCTIF 函数，可以对结果集进行去重。例如：SELECT DISTINCTIF * FROM table_name。
4. **使用合适的哈希函数**：在进行分布式计算时，可以使用哈希函数对数据进行分片，从而减少重复数据的出现。ClickHouse 中提供了多种哈希函数，如cityHash64、sipHash64等。

需要注意的是，在使用 DISTINCT 关键字和 GROUP BY 关键字时，会增加查询的计算量和响应时间，因此需要根据具体的查询场景来选择合适的方式。同时，在使用哈希函数时，也需要注意哈希函数的选择和使用方法，以避免出现重复数据的情况。







# 12.实时数据处理过程中，设计表关联，如何实现Flink表与mysql表进行关联？

在 Flink 中，可以通过 Flink SQL 的方式来实现 Flink 表与 MySQL 表的关联。具体来说，可以使用 Flink SQL 的 CONNECTOR 功能将 MySQL 表导入到 Flink 中，然后使用 SQL 语句进行表关联操作。

1. 导入 MySQL 表到 Flink 中：可以使用 Flink SQL 的 CONNECTOR 功能，将 MySQL 表导入到 Flink 中。具体来说，可以使用 Flink 提供的 JDBC CONNECTOR，连接到 MySQL 数据库，并将 MySQL 表作为 Flink 表进行导入
2. 在 Flink 中进行表关联操作：在导入 MySQL 表之后，可以使用 SQL 语句进行表关联操作



# 13. 两个流同时进行join，其中一个流在更新，如何实现；版本表问题？

在 Flink 中，可以使用 Stateful Stream Processing 来实现流的 join 操作，其中一个流在更新的情况下，可以使用状态管理来实现。

具体实现方式如下：

1. 将需要更新的流作为主流，另一个流作为次要流；
2. 使用 Flink 提供的 Stateful Stream Processing API 来管理状态；
3. 在主流中，将需要更新的数据存储到状态中；
4. 在次要流中，使用状态中的数据进行 join 操作；
5. 将 join 后的结果输出。

版本表问题，可以使用 Flink 的状态管理来解决。在 Flink 中，可以使用不同的状态类型来存储版本表数据，例如 ValueState、ListState、MapState 等。

具体实现方式如下：

1. 将版本表数据存储到状态中；
2. 在主流中，使用状态中的版本号和次要流中的版本号进行比较；
3. 如果版本号相同，则进行 join 操作；
4. 如果版本号不同，则将主流中的数据存储到状态中，等待次要流中的数据更新；
5. 在次要流中，更新版本号，并将数据存储到状态中；
6. 当次要流中的数据更新后，再次比较版本号，如果版本号相同，则进行 join 操作。





# 14. Flink中Barea,是否需要接受到所有算子才执行？

Barea 是 Flink 中的一种流量控制算子，用于控制数据流的速率。它可以在数据流经过它之前，对数据进行缓存，从而实现流量控制的效果。

Barea 算子不需要接收到所有算子才执行，它会根据配置的参数来控制流量速率。具体来说，Barea 算子会根据以下参数来控制流量速率：

1. bufferTimeout：缓存超时时间，即缓存数据的最长时间；
2. maxCount：缓存数据的最大数量；
3. maxBytes：缓存数据的最大字节数；
4. maxMessagesPerSecond：每秒处理的最大消息数。

Barea 算子会根据这些参数来控制数据流的速率，如果缓存中的数据已经达到了最大数量、最大字节数或者最大消息数，那么 Barea 算子就会暂停接收数据，直到缓存中的数据被处理完毕。因此，Barea 算子不需要接收到所有算子才执行，而是根据参数来控制数据流的速率，保证数据流的平稳处理。







# 15. Chickpoint是否支持事务？

Chickpoint 是 Flink 中的一个可插拔式的检查点（checkpoint）机制，用于实现 Flink 应用程序的容错机制。它可以将应用程序的状态定期保存到持久化存储器中，以便在发生故障时进行恢复。

Chickpoint 本身并不支持事务，但是可以与 Flink 的事务性处理功能结合使用，实现更加可靠的容错机制。具体来说，可以使用 Flink 的事务性处理功能来保证应用程序的状态更新与数据写入的原子性，而使用 Chickpoint 来定期保存应用程序的状态。

在 Flink 中，可以使用 Chickpoint 和 Flink 的事务性处理功能相结合的方式来实现 Exactly-Once 语义。具体来说，可以使用 Flink 的两阶段提交（Two-Phase-Commit）协议来保证事务的原子性，而使用 Chickpoint 来定期保存应用程序的状态，以便在发生故障时进行恢复。

需要注意的是，Chickpoint 本身并不支持事务，因此在使用 Chickpoint 时，需要结合 Flink 的事务性处理功能来实现可靠的容错机制。





# 16. Flink部署方式，客户端提交任务方式？

Flink可以使用以下几种方式进行部署：

1. Standalone模式：在单个节点上启动Flink集群，适合本地开发和测试。

2. YARN模式：在Hadoop YARN上运行Flink集群，可以和Hadoop生态系统无缝集成。

3. Mesos模式：在Mesos上运行Flink集群，可以和Mesos生态系统无缝集成。

4. Kubernetes模式：在Kubernetes上运行Flink集群，可以和Kubernetes生态系统无缝集成。

5. 云服务模式：Flink可以在各种云平台上运行，例如Amazon EMR、Google Cloud Dataflow等。

客户端提交任务的方式有两种：

1. 命令行提交：使用flink run命令提交任务，例如：

   ```
   ./bin/flink run -c com.example.MyJob /path/to/my/job.jar
   ```

2. Web UI提交：通过Flink的Web UI上传和提交任务。首先在Web UI的"Submit new Job"页面上传任务jar包，然后在"Job Configuration"页面设置任务参数并提交任务。



# 17. Flink被称作流批一体，从哪个版本开始，真正实现流批一体的？说说你的理解。

Flink从版本1.2开始真正实现了流批一体的概念。在这个版本中，Flink引入了DataStream API，它使得用户可以像处理批处理数据一样处理流式数据。同时，Flink提供了DataSet API和DataStream API之间的无缝转换，使得用户可以在同一个程序中处理批处理数据和流式数据。

在之后的版本中，Flink继续增强了流批一体的能力。例如，Flink 1.9版本引入了动态表格API，使得用户可以将流数据转换为表格数据，并在SQL或Table API中进行查询和分析。Flink 1.11版本引入了Flink SQL的流批一体特性，使得用户可以使用相同的SQL语法来处理批处理数据和流式数据。

在我看来，Flink实现流批一体的关键在于其统一的API和底层引擎。Flink的API和引擎都是基于数据流的概念设计的，这使得用户可以使用相同的API和引擎来处理批处理数据和流式数据。同时，Flink的引擎支持事件时间和处理时间两种时间概念，可以处理无界数据流和有界数据集。这些特性使得Flink成为一个真正意义上的流批一体的计算框架。

主流版本

```
<!-- https://mvnrepository.com/artifact/org.apache.flink/flink-streaming-scala -->
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-streaming-scala_2.12</artifactId>
    <version>1.15.2</version>
    <scope>provided</scope>
</dependency>

```

# 18. Flink SQL 处理流程

Flink SQL是Flink提供的一种处理流式数据的SQL语言，它能够将流式数据转换成数据表格，并基于SQL语句进行查询和分析。下面是Flink SQL处理流程的概述：

1. 数据源：Flink SQL可以从多种数据源中获取数据，例如Kafka、Kinesis、文件系统等。用户可以使用Flink的DataStream API或Table API将数据源转换为表格数据。

2. 数据转换：Flink SQL支持多种数据转换操作，例如投影、过滤、聚合等。这些操作可以在SQL语句中进行指定，也可以在Table API中进行编程。

3. 查询优化：Flink SQL使用基于规则的查询优化器来优化查询计划，例如选择最优的算子、重写查询语句等。

4. 执行计划：Flink SQL将查询语句转换成执行计划，执行计划包括多个算子，每个算子都是一个Flink任务。

5. 任务调度：Flink SQL使用Flink的任务调度器来调度执行计划中的任务，任务调度器将任务分配给Flink集群中的任务管理器进行执行。

6. 数据输出：Flink SQL将计算结果输出到指定的数据源中，例如Kafka、HDFS等。

总的来说，Flink SQL的处理流程可以分为数据源、数据转换、查询优化、执行计划、任务调度和数据输出六个阶段。这些阶段共同构成了Flink SQL处理流式数据的完整流程。

# 19.Flink常用的时间窗口

1. **滚动窗口**（Tumbling Window）：将数据按照固定大小的窗口进行分组，每个窗口的数据不重叠。例如，每10秒钟统计一次过去10秒钟的数据。
2. **滑动窗口**（Sliding Window）：将数据按照固定大小的窗口进行分组，每个窗口的数据可以有重叠。例如，每10秒钟统计一次过去20秒钟的数据，每个窗口的时间跨度为10秒。
3. **会话窗口**（Session Window）：将数据按照一定的时间间隔进行分组，当一段时间内没有数据输入时，该窗口结束。例如，如果10秒钟内没有数据输入，则认为该窗口结束。
4. **全局窗口**（Global Window）：将所有数据放入同一个窗口中进行处理，适用于数据量较小的场景。
5. **增量聚合窗口**（Incremental Aggregation Window）：在窗口中每次新增一条数据时，不需要重新计算之前的所有数据，而是只需要计算新增的数据即可。适用于数据量较大的场景。

# 20.  Flink常用数据处理API

**API大类**

1. DataStream API：用于处理无限流数据，支持实时的数据处理和计算。
2. DataSet API：用于处理有限的数据集，通常从文件或数据库中读取数据，支持批处理和离线计算。
3. Table API 和 SQL：提供了类似于 SQL 的查询语言，可以方便地对流和批数据进行查询和转换。
4. Stateful Stream Processing API：用于实现有状态的流处理，例如对数据进行累加、去重、计数等操作。
5. CEP API：用于实现复杂事件处理，例如对事件流进行模式匹配、时间窗口计算等操作。
6. Graph Processing API：用于实现图计算，例如对社交网络进行分析、推荐系统等。
7. Machine Learning API：用于实现机器学习算法，例如分类、聚类、回归等。
8. Gelly API：用于实现图分析和图算法，例如 PageRank、图聚类等操作。

**常用Transform和Action**

在 Flink 中，常见的 transform 和 action 包括：

Transform：

1. map(Function)：对数据集中的每个元素应用指定的函数，返回一个新的数据集。
2. filter(Function)：根据指定的条件过滤数据集中的元素，返回一个新的数据集。
3. flatMap(Function)：将数据集中的每个元素转换为一个或多个元素，返回一个新的数据集。
4. groupBy(KeySelector)：按照指定的键对数据集进行分组，返回一个 GroupedDataStream。
5. keyBy(KeySelector)：按照指定的键对数据集进行分区，返回一个 KeyedDataStream。
6. reduce(Function)：对数据集中的元素进行聚合操作，返回一个新的数据集。

Action：

1. print()：将数据集中的元素打印到控制台。
2. collect()：将数据集中的所有元素收集到一个 List 中。
3. count()：返回数据集中元素的个数。
4. sum()：对数据集中的元素进行求和操作。
5. min()：返回数据集中的最小元素。
6. max()：返回数据集中的最大元素。
7. writeAsText()：将数据集中的元素写入到指定的文件中。

# 21. Kafka会在以下情况下触发rebalance机制

1. 消费者组内新增或删除消费者。
2. 消费者组内有消费者宕机或重启。
3. 消费者组内有消费者的订阅主题发生变化。
4. 消费者组的消费者心跳超时，被认为已经宕机。

在以上情况下，Kafka会触发rebalance机制，重新分配分区给消费者，确保每个消费者只消费自己被分配的分区。

# 22. Flink在什么情况下会出现算子链

Flink中的算子链是指一系列相互连接的算子（操作符）在执行时被组合在一起形成的链式结构。**算子链可以提高执行效率，减少数据序列化和网络传输开销**。

在以下情况下，Flink会自动创建算子链：
1. 连续的相同类型的算子：如果相邻的算子类型相同且没有其他操作符干扰，Flink会将它们连接成一个算子链。
2. 连续的相同函数的算子：如果相邻的算子使用相同的函数，Flink会将它们连接成一个算子链。
3. 算子的并行度相同：如果相邻的算子的并行度相同，Flink会将它们连接成一个算子链。
4. 算子之间没有shuffle操作：如果相邻的算子之间没有需要进行数据重分区的shuffle操作，Flink会将它们连接成一个算子链。

需要注意的是，算子链并不是一定会出现的，它是由Flink的优化器根据执行计划和配置进行决策的。在某些情况下，算子链可能会被打破，例如当设置了特定的优化参数或使用了某些特殊的算子。
